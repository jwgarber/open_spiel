game: geodesic_y

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Geodesic Y Connection Game"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["ansi_color_output", "base_size"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "geodesic_y"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 63
PolicyTensorShape() = [63]
MaxChanceOutcomes() = 0
GetParameters() = {ansi_color_output=False,base_size=7}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 63]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 189
MaxGameLength() = 63
ToString() = "geodesic_y()"

# State 0
# Player 1:
# Player 2:
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "Player 1: \nPlayer 2: \n"
ObservationString(1) = "Player 1: \nPlayer 2: \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "7"
action: 7

# State 1
# Player 1: 7
# Player 2:
IsTerminal() = False
History() = [7]
HistoryString() = "7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7"
InformationStateString(1) = "7"
ObservationString(0) = "Player 1: 7 \nPlayer 2: \n"
ObservationString(1) = "Player 1: 7 \nPlayer 2: \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "1", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "44"
action: 44

# State 2
# Player 1: 7
# Player 2: 44
IsTerminal() = False
History() = [7, 44]
HistoryString() = "7 44"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44"
InformationStateString(1) = "7 44"
ObservationString(0) = "Player 1: 7 \nPlayer 2: 44 \n"
ObservationString(1) = "Player 1: 7 \nPlayer 2: 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "1", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "15"
action: 15

# State 3
# Player 1: 7 15
# Player 2: 44
IsTerminal() = False
History() = [7, 44, 15]
HistoryString() = "7 44 15"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15"
InformationStateString(1) = "7 44 15"
ObservationString(0) = "Player 1: 7 15 \nPlayer 2: 44 \n"
ObservationString(1) = "Player 1: 7 15 \nPlayer 2: 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "1", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "1"
action: 1

# State 4
# Player 1: 7 15
# Player 2: 1 44
IsTerminal() = False
History() = [7, 44, 15, 1]
HistoryString() = "7 44 15 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1"
InformationStateString(1) = "7 44 15 1"
ObservationString(0) = "Player 1: 7 15 \nPlayer 2: 1 44 \n"
ObservationString(1) = "Player 1: 7 15 \nPlayer 2: 1 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "36"
action: 36

# State 5
# Player 1: 7 15 36
# Player 2: 1 44
IsTerminal() = False
History() = [7, 44, 15, 1, 36]
HistoryString() = "7 44 15 1 36"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36"
InformationStateString(1) = "7 44 15 1 36"
ObservationString(0) = "Player 1: 7 15 36 \nPlayer 2: 1 44 \n"
ObservationString(1) = "Player 1: 7 15 36 \nPlayer 2: 1 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "30"
action: 30

# State 6
# Player 1: 7 15 36
# Player 2: 1 30 44
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30]
HistoryString() = "7 44 15 1 36 30"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30"
InformationStateString(1) = "7 44 15 1 36 30"
ObservationString(0) = "Player 1: 7 15 36 \nPlayer 2: 1 30 44 \n"
ObservationString(1) = "Player 1: 7 15 36 \nPlayer 2: 1 30 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "21"
action: 21

# State 7
# Player 1: 7 15 21 36
# Player 2: 1 30 44
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21]
HistoryString() = "7 44 15 1 36 30 21"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21"
InformationStateString(1) = "7 44 15 1 36 30 21"
ObservationString(0) = "Player 1: 7 15 21 36 \nPlayer 2: 1 30 44 \n"
ObservationString(1) = "Player 1: 7 15 21 36 \nPlayer 2: 1 30 44 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "54"
action: 54

# State 8
# Player 1: 7 15 21 36
# Player 2: 1 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54]
HistoryString() = "7 44 15 1 36 30 21 54"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54"
InformationStateString(1) = "7 44 15 1 36 30 21 54"
ObservationString(0) = "Player 1: 7 15 21 36 \nPlayer 2: 1 30 44 54 \n"
ObservationString(1) = "Player 1: 7 15 21 36 \nPlayer 2: 1 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉◉◯◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "51", "52", "53", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "51"
action: 51

# State 9
# Player 1: 7 15 21 36 51
# Player 2: 1 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51]
HistoryString() = "7 44 15 1 36 30 21 54 51"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51"
ObservationString(0) = "Player 1: 7 15 21 36 51 \nPlayer 2: 1 30 44 54 \n"
ObservationString(1) = "Player 1: 7 15 21 36 51 \nPlayer 2: 1 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "19", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "19"
action: 19

# State 10
# Player 1: 7 15 21 36 51
# Player 2: 1 19 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19]
HistoryString() = "7 44 15 1 36 30 21 54 51 19"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19"
ObservationString(0) = "Player 1: 7 15 21 36 51 \nPlayer 2: 1 19 30 44 54 \n"
ObservationString(1) = "Player 1: 7 15 21 36 51 \nPlayer 2: 1 19 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "13", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "13"
action: 13

# State 11
# Player 1: 7 13 15 21 36 51
# Player 2: 1 19 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 \nPlayer 2: 1 19 30 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 \nPlayer 2: 1 19 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "9", "10", "11", "12", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "9"
action: 9

# State 12
# Player 1: 7 13 15 21 36 51
# Player 2: 1 9 19 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 \nPlayer 2: 1 9 19 30 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 \nPlayer 2: 1 9 19 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61", "62"]

# Apply action "62"
action: 62

# State 13
# Player 1: 7 13 15 21 36 51 62
# Player 2: 1 9 19 30 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 62 \nPlayer 2: 1 9 19 30 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 62 \nPlayer 2: 1 9 19 30 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◉◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "37", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61"]

# Apply action "37"
action: 37

# State 14
# Player 1: 7 13 15 21 36 51 62
# Player 2: 1 9 19 30 37 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 62 \nPlayer 2: 1 9 19 30 37 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 62 \nPlayer 2: 1 9 19 30 37 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◉◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "58", "59", "60", "61"]

# Apply action "58"
action: 58

# State 15
# Player 1: 7 13 15 21 36 51 58 62
# Player 2: 1 9 19 30 37 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 58 62 \nPlayer 2: 1 9 19 30 37 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 58 62 \nPlayer 2: 1 9 19 30 37 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "16", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "59", "60", "61"]

# Apply action "16"
action: 16

# State 16
# Player 1: 7 13 15 21 36 51 58 62
# Player 2: 1 9 16 19 30 37 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16"
ObservationString(0) = "Player 1: 7 13 15 21 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◉◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "28", "29", "31", "32", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "59", "60", "61"]

# Apply action "28"
action: 28

# State 17
# Player 1: 7 13 15 21 28 36 51 58 62
# Player 2: 1 9 16 19 30 37 44 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28"
ObservationString(0) = "Player 1: 7 13 15 21 28 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◉◉◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "32", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "52", "53", "55", "56", "57", "59", "60", "61"]

# Apply action "52"
action: 52

# State 18
# Player 1: 7 13 15 21 28 36 51 58 62
# Player 2: 1 9 16 19 30 37 44 52 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52"
ObservationString(0) = "Player 1: 7 13 15 21 28 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◉◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◉◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◉◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "32", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "53", "55", "56", "57", "59", "60", "61"]

# Apply action "32"
action: 32

# State 19
# Player 1: 7 13 15 21 28 32 36 51 58 62
# Player 2: 1 9 16 19 30 37 44 52 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◉◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◯◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◉◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "53", "55", "56", "57", "59", "60", "61"]

# Apply action "53"
action: 53

# State 20
# Player 1: 7 13 15 21 28 32 36 51 58 62
# Player 2: 1 9 16 19 30 37 44 52 53 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 36 51 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◉◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◉◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 56, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "56", "57", "59", "60", "61"]

# Apply action "56"
action: 56

# State 21
# Player 1: 7 13 15 21 28 32 36 51 56 58 62
# Player 2: 1 9 16 19 30 37 44 52 53 54
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◉◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◉◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60, 61]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60", "61"]

# Apply action "61"
action: 61

# State 22
# Player 1: 7 13 15 21 28 32 36 51 56 58 62
# Player 2: 1 9 16 19 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◉◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "35", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "35"
action: 35

# State 23
# Player 1: 7 13 15 21 28 32 35 36 51 56 58 62
# Player 2: 1 9 16 19 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 35 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 35 36 51 56 58 62 \nPlayer 2: 1 9 16 19 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◉◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "8", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "8"
action: 8

# State 24
# Player 1: 7 13 15 21 28 32 35 36 51 56 58 62
# Player 2: 1 8 9 16 19 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8"
ObservationString(0) = "Player 1: 7 13 15 21 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◉◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "27", "29", "31", "33", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "27"
action: 27

# State 25
# Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62
# Player 2: 1 8 9 16 19 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◯◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◉◉◉◉◯◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 10, 11, 12, 14, 17, 18, 20, 22, 23, 24, 25, 26, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "10", "11", "12", "14", "17", "18", "20", "22", "23", "24", "25", "26", "29", "31", "33", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "23"
action: 23

# State 26
# Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62
# Player 2: 1 8 9 16 19 23 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◉◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 26, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "26", "29", "31", "33", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "33"
action: 33

# State 27
# Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62
# Player 2: 1 8 9 16 19 23 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62 \nPlayer 2: 1 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◉◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "5", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "26", "29", "31", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "5"
action: 5

# State 28
# Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62
# Player 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◉◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "26", "29", "31", "34", "38", "39", "40", "41", "42", "43", "45", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "45"
action: 45

# State 29
# Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62
# Player 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◉◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "26", "29", "31", "34", "38", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "26"
action: 26

# State 30
# Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62
# Player 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 62 \nPlayer 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◉
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◉◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 29, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 59, 60]
StringLegalActions() = ["0", "2", "3", "4", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "29", "31", "34", "38", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "59", "60"]

# Apply action "59"
action: 59

# State 31
# Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◯◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◉◯◉◉◉◯◉◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 6, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 29, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["0", "2", "3", "4", "6", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "29", "31", "34", "38", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "6"
action: 6

# State 32
# Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◉◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 29, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["0", "2", "3", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "29", "31", "34", "38", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "29"
action: 29

# State 33
# Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◉◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["0", "2", "3", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "38", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "38"
action: 38

# State 34
# Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38"
ObservationString(0) = "Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationTensor(0): ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◉◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["0", "2", "3", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "0"
action: 0

# State 35
# Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0"
ObservationString(0) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◯◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◯◉◉◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 3, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["2", "3", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "3"
action: 3

# State 36
# Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3"
ObservationString(0) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◯◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◉◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 57, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "57", "60"]

# Apply action "57"
action: 57

# State 37
# Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57"
ObservationString(0) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◉◉◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "48", "49", "50", "55", "60"]

# Apply action "48"
action: 48

# State 38
# Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48"
ObservationString(0) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◯◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◉◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 20, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 49, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "20", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "49", "50", "55", "60"]

# Apply action "20"
action: 20

# State 39
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◉◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 22, 24, 25, 31, 34, 39, 40, 41, 42, 43, 46, 47, 49, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "22", "24", "25", "31", "34", "39", "40", "41", "42", "43", "46", "47", "49", "50", "55", "60"]

# Apply action "25"
action: 25

# State 40
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◉◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 22, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 49, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "22", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "49", "50", "55", "60"]

# Apply action "49"
action: 49

# State 41
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◯◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◉◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 22, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "22", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "50", "55", "60"]

# Apply action "22"
action: 22

# State 42
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◯◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◉◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 50, 55, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "50", "55", "60"]

# Apply action "55"
action: 55

# State 43
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◯◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◉◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 18, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 50, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "18", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "50", "60"]

# Apply action "18"
action: 18

# State 44
# Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18"
ObservationString(0) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◯◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◉◯◉◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 10, 11, 12, 14, 17, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 50, 60]
StringLegalActions() = ["2", "4", "10", "11", "12", "14", "17", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "50", "60"]

# Apply action "4"
action: 4

# State 45
# Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4"
ObservationString(0) = "Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◉◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 10, 11, 12, 14, 17, 24, 31, 34, 39, 40, 41, 42, 43, 46, 47, 50, 60]
StringLegalActions() = ["2", "10", "11", "12", "14", "17", "24", "31", "34", "39", "40", "41", "42", "43", "46", "47", "50", "60"]

# Apply action "31"
action: 31

# State 46
# Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31"
ObservationString(0) = "Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◯◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◉◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◯◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◉◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 10, 11, 12, 14, 17, 24, 34, 39, 40, 41, 42, 43, 46, 47, 50, 60]
StringLegalActions() = ["2", "10", "11", "12", "14", "17", "24", "34", "39", "40", "41", "42", "43", "46", "47", "50", "60"]

# Apply action "2"
action: 2

# State 47
# Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2"
ObservationString(0) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◯◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◉◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 14, 17, 24, 34, 39, 40, 41, 42, 43, 46, 47, 50, 60]
StringLegalActions() = ["10", "11", "12", "14", "17", "24", "34", "39", "40", "41", "42", "43", "46", "47", "50", "60"]

# Apply action "47"
action: 47

# State 48
# Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47"
ObservationString(0) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◯◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◉◉◉◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 14, 17, 24, 34, 39, 40, 41, 42, 43, 46, 50, 60]
StringLegalActions() = ["10", "11", "12", "14", "17", "24", "34", "39", "40", "41", "42", "43", "46", "50", "60"]

# Apply action "40"
action: 40

# State 49
# Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40"
ObservationString(0) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◉◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◯◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◉◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 14, 17, 24, 34, 39, 41, 42, 43, 46, 50, 60]
StringLegalActions() = ["10", "11", "12", "14", "17", "24", "34", "39", "41", "42", "43", "46", "50", "60"]

# Apply action "42"
action: 42

# State 50
# Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42"
ObservationString(0) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◯◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◉◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 14, 17, 24, 34, 39, 41, 43, 46, 50, 60]
StringLegalActions() = ["10", "11", "12", "14", "17", "24", "34", "39", "41", "43", "46", "50", "60"]

# Apply action "14"
action: 14

# State 51
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◯◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◉◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [10, 11, 12, 17, 24, 34, 39, 41, 43, 46, 50, 60]
StringLegalActions() = ["10", "11", "12", "17", "24", "34", "39", "41", "43", "46", "50", "60"]

# Apply action "10"
action: 10

# State 52
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◯◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◉◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 12, 17, 24, 34, 39, 41, 43, 46, 50, 60]
StringLegalActions() = ["11", "12", "17", "24", "34", "39", "41", "43", "46", "50", "60"]

# Apply action "43"
action: 43

# State 53
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◯◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 12, 17, 24, 34, 39, 41, 46, 50, 60]
StringLegalActions() = ["11", "12", "17", "24", "34", "39", "41", "46", "50", "60"]

# Apply action "60"
action: 60

# State 54
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◯◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 12, 17, 24, 34, 39, 41, 46, 50]
StringLegalActions() = ["11", "12", "17", "24", "34", "39", "41", "46", "50"]

# Apply action "50"
action: 50

# State 55
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60, 50]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◯◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [11, 12, 17, 24, 34, 39, 41, 46]
StringLegalActions() = ["11", "12", "17", "24", "34", "39", "41", "46"]

# Apply action "11"
action: 11

# State 56
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60, 50, 11]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◯◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [12, 17, 24, 34, 39, 41, 46]
StringLegalActions() = ["12", "17", "24", "34", "39", "41", "46"]

# Apply action "41"
action: 41

# State 57
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60, 50, 11, 41]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◯◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [12, 17, 24, 34, 39, 46]
StringLegalActions() = ["12", "17", "24", "34", "39", "46"]

# Apply action "39"
action: 39

# State 58
# Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61
IsTerminal() = False
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60, 50, 11, 41, 39]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39"
ObservationString(0) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◯◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [12, 17, 24, 34, 46]
StringLegalActions() = ["12", "17", "24", "34", "46"]

# Apply action "12"
action: 12

# State 59
# Player 1: 0 2 4 7 12 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62
# Player 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61
IsTerminal() = True
History() = [7, 44, 15, 1, 36, 30, 21, 54, 51, 19, 13, 9, 62, 37, 58, 16, 28, 52, 32, 53, 56, 61, 35, 8, 27, 23, 33, 5, 45, 26, 59, 6, 29, 38, 0, 3, 57, 48, 20, 25, 49, 22, 55, 18, 4, 31, 2, 47, 40, 42, 14, 10, 43, 60, 50, 11, 41, 39, 12]
HistoryString() = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39 12"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39 12"
InformationStateString(1) = "7 44 15 1 36 30 21 54 51 19 13 9 62 37 58 16 28 52 32 53 56 61 35 8 27 23 33 5 45 26 59 6 29 38 0 3 57 48 20 25 49 22 55 18 4 31 2 47 40 42 14 10 43 60 50 11 41 39 12"
ObservationString(0) = "Player 1: 0 2 4 7 12 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61 \n"
ObservationString(1) = "Player 1: 0 2 4 7 12 13 14 15 20 21 27 28 29 32 33 35 36 40 41 43 45 49 50 51 55 56 57 58 59 62 \nPlayer 2: 1 3 5 6 8 9 10 11 16 18 19 22 23 25 26 30 31 37 38 39 42 44 47 48 52 53 54 60 61 \n"
ObservationTensor(0): ◉◯◉◯◉◯◯◉◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◉◯◉◯◉◉◯◉◉◉◉◯◯◯◯◉◯◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◯◉◯◯◉◉◯◯◯◉◉◉◯◯◯◯◯◉◉◯
                      ◉◯◉◯◉◯◯◉◯◯◯◯◉◉◉◉◯◯◯◯◉◉◯◯◯◯◯◉◉◉◯◯◉◉◯◉◉◯◯◯◉◉◯◉◯◉◯◯◯◉◉◉◯◯◯◉◉◉◉◉◯◯◉
                      ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
Rewards() = [1.0, -1.0]
Returns() = [1.0, -1.0]
